#!/usr/bin/env python3
"""
Leaderboard Export Bridge for p(Doom)1 Website Integration

This script bridges the gap between the game's leaderboard system and the website
by creating a compatible export format until the main repository implements
the web export functionality.

Usage:
    python scripts/export-leaderboard-bridge.py
    python scripts/export-leaderboard-bridge.py --seed specific-seed
    python scripts/export-leaderboard-bridge.py --all-seeds
"""

import json
import argparse
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional
import random


class LeaderboardBridge:
    """Bridge between game leaderboard format and website display format."""
    
    def __init__(self):
        self.website_data_dir = Path(__file__).parent.parent / "public" / "leaderboard" / "data"
        self.output_file = self.website_data_dir / "leaderboard.json"
        
    def create_realistic_leaderboard_data(self, seed: str = "demo-seed-v0.4.1", num_entries: int = 15) -> Dict[str, Any]:
        """
        Create realistic leaderboard data that matches the actual game format.
        
        This simulates what the game's export function should produce.
        """
        
        # Lab names from the actual game (from pdoom1 repository)
        lab_names = [
            "Anthropic Safety Labs", "OpenAI Research", "DeepMind Safety", 
            "MIRI Research", "Berkeley CHAI", "Future of Humanity Institute",
            "Machine Intelligence Research", "AI Safety Research Group",
            "Alignment Research Center", "Center for AI Safety",
            "Existential Risk Research", "Technical AI Safety",
            "Cooperative AI Foundation", "AI Governance Institute",
            "Long-Term Future Fund"
        ]
        
        entries = []
        base_date = datetime.now() - timedelta(days=random.randint(1, 7))
        
        for i in range(num_entries):
            # Create realistic score distribution (higher scores less common)
            if i == 0:
                score = random.randint(80, 95)  # Top score
            elif i < 3:
                score = random.randint(70, 85)  # Top 3
            elif i < 8:
                score = random.randint(50, 75)  # Middle tier
            else:
                score = random.randint(25, 55)  # Lower tier
            
            # Realistic game session data
            duration_minutes = random.uniform(15, 120)  # 15 minutes to 2 hours
            
            # Economic metrics based on score performance
            performance_factor = score / 100.0
            final_money = int(performance_factor * random.uniform(500000, 3000000))
            final_staff = int(performance_factor * random.randint(10, 60))
            final_doom = round(random.uniform(10, 60) * (1.5 - performance_factor), 1)
            final_reputation = round(performance_factor * random.uniform(60, 95), 1)
            final_compute = int(performance_factor * random.randint(50000, 200000))
            
            entry = {
                "score": score,
                "player_name": lab_names[i % len(lab_names)],
                "date": (base_date - timedelta(hours=random.randint(0, 168))).isoformat() + "Z",
                "level_reached": score,  # Same as score in current game
                "game_mode": "Bootstrap_v0.4.1",
                "duration_seconds": round(duration_minutes * 60, 1),
                "entry_uuid": f"uuid-{i+1:03d}",
                "final_doom": final_doom,
                "final_money": final_money,
                "final_staff": final_staff,
                "final_reputation": final_reputation,
                "final_compute": final_compute,
                "research_papers_published": random.randint(0, min(12, score // 10)),
                "technical_debt_accumulated": random.randint(0, max(5, 100 - score))
            }
            entries.append(entry)
        
        # Sort by score (highest first)
        entries.sort(key=lambda x: x["score"], reverse=True)
        
        return {
            "meta": {
                "generated": datetime.now().isoformat() + "Z",
                "game_version": "v0.4.1",
                "total_seeds": 1,
                "total_players": len(set(entry["player_name"] for entry in entries)),
                "export_source": "leaderboard-bridge",
                "note": "Generated by website bridge until game export is implemented"
            },
            "seed": seed,
            "economic_model": "Bootstrap_v0.4.1",
            "entries": entries
        }
    
    def export_leaderboard(self, seed: Optional[str] = None, refresh: bool = True) -> Path:
        """
        Export leaderboard data for website consumption.
        
        Args:
            seed: Specific seed to export (None for default demo seed)
            refresh: Whether to generate fresh data
            
        Returns:
            Path to the exported file
        """
        if not refresh and self.output_file.exists():
            print(f"DATA: Using existing leaderboard data: {self.output_file}")
            return self.output_file
        
        # Ensure output directory exists
        self.output_file.parent.mkdir(parents=True, exist_ok=True)
        
        # Generate or load leaderboard data
        seed = seed or "demo-competitive-seed"
        leaderboard_data = self.create_realistic_leaderboard_data(seed)
        
        # Write to output file
        with open(self.output_file, 'w', encoding='utf-8') as f:
            json.dump(leaderboard_data, f, indent=2, ensure_ascii=False)
        
        print(f"SUCCESS: Exported leaderboard data to: {self.output_file}")
        print(f"SEED: Seed: {seed}")
        print(f"ENTRIES: Entries: {len(leaderboard_data['entries'])}")
        print(f"TOP: Top Score: {leaderboard_data['entries'][0]['score']} turns")
        print(f"LEADER: Leader: {leaderboard_data['entries'][0]['player_name']}")
        
        return self.output_file
    
    def validate_export(self) -> bool:
        """Validate that the exported data matches website expectations."""
        if not self.output_file.exists():
            print("ERROR: No leaderboard data found to validate")
            return False
        
        try:
            with open(self.output_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # Check required structure
            required_fields = ["meta", "seed", "economic_model", "entries"]
            for field in required_fields:
                if field not in data:
                    print(f"❌ Missing required field: {field}")
                    return False
            
            # Check entries structure
            if not data["entries"]:
                print("❌ No entries found in leaderboard")
                return False
            
            entry = data["entries"][0]
            required_entry_fields = [
                "score", "player_name", "date", "level_reached", 
                "game_mode", "duration_seconds", "entry_uuid"
            ]
            
            for field in required_entry_fields:
                if field not in entry:
                    print(f"❌ Missing required entry field: {field}")
                    return False
            
            print("SUCCESS: Leaderboard data structure validation passed")
            print(f"COMPATIBLE: Format compatible with game v{data['meta'].get('game_version', 'unknown')}")
            return True
            
        except Exception as e:
            print(f"ERROR: Validation failed: {e}")
            return False
    
    def get_bridge_status(self) -> Dict[str, Any]:
        """Get current status of the leaderboard bridge."""
        status = {
            "bridge_active": True,
            "output_file": str(self.output_file),
            "file_exists": self.output_file.exists(),
            "last_modified": None,
            "entries_count": 0,
            "seed": None,
            "ready_for_integration": False
        }
        
        if self.output_file.exists():
            try:
                stat = self.output_file.stat()
                status["last_modified"] = datetime.fromtimestamp(stat.st_mtime).isoformat()
                
                with open(self.output_file, 'r') as f:
                    data = json.load(f)
                    
                status["entries_count"] = len(data.get("entries", []))
                status["seed"] = data.get("seed")
                status["ready_for_integration"] = True
                
            except Exception as e:
                status["error"] = str(e)
        
        return status


def main():
    """CLI interface for the leaderboard bridge."""
    parser = argparse.ArgumentParser(description="p(Doom)1 Leaderboard Export Bridge")
    parser.add_argument("--seed", type=str, help="Specific seed to export")
    parser.add_argument("--refresh", action="store_true", 
                       help="Force refresh of leaderboard data")
    parser.add_argument("--validate", action="store_true",
                       help="Validate existing leaderboard data")
    parser.add_argument("--status", action="store_true",
                       help="Show bridge status")
    
    args = parser.parse_args()
    
    bridge = LeaderboardBridge()
    
    if args.status:
        status = bridge.get_bridge_status()
        print("🌉 Leaderboard Bridge Status:")
        print(f"   📄 Output file: {status['output_file']}")
        print(f"   📊 Entries: {status['entries_count']}")
        print(f"   🎲 Seed: {status['seed']}")
        print(f"   ⏰ Last updated: {status.get('last_modified', 'Never')}")
        print(f"   ✅ Ready: {status['ready_for_integration']}")
        return
    
    if args.validate:
        success = bridge.validate_export()
        sys.exit(0 if success else 1)
    
    # Export leaderboard data
    try:
        output_file = bridge.export_leaderboard(seed=args.seed, refresh=args.refresh)
        
        # Automatically validate after export
        if bridge.validate_export():
            print("\n🎯 Next steps:")
            print("   1. View leaderboard: http://localhost:5173/leaderboard/")
            print("   2. Test integration: npm run test:health")
            print("   3. Deploy changes when ready")
        else:
            print("\n❌ Export completed but validation failed")
            sys.exit(1)
            
    except Exception as e:
        print(f"❌ Export failed: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()